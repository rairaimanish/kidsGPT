import React, { useState } from 'react';
import axios from 'axios';
import './App.css';  // Ensure the custom CSS file is imported for styling

function App() {
  const [selectedFile, setSelectedFile] = useState(null);
  const [typedInput, setTypedInput] = useState("");  // New state for typed text input
  const [isLoading, setIsLoading] = useState(false);
  const [messages, setMessages] = useState([]);
  const [isProcessing, setIsProcessing] = useState(false);

  // Handle file input change
  const handleFileChange = (e) => {
    setSelectedFile(e.target.files[0]);
  };

  // Handle typed input change
  const handleTypedInputChange = (e) => {
    setTypedInput(e.target.value);
  };

  // Step 1: Transcribe the audio and display the user's transcription
  const handleTranscribe = async () => {
    if (!selectedFile) {
      alert("Please select an audio file first.");
      return;
    }

    const formData = new FormData();
    formData.append('audio', selectedFile);

    try {
      setIsLoading(true);

      // Send the audio file to Flask backend for transcription
      const transcriptionResponse = await axios.post('http://localhost:5000/api/transcribe', formData);
      const { transcription } = transcriptionResponse.data;

      // Step 1: Display the user's transcription
      setMessages((prevMessages) => [
        ...prevMessages,
        { role: 'user', content: transcription }  // User's voice transcription
      ]);

      return transcription;  // Return transcription to be used in next step
    } catch (error) {
      console.error('Error:', error);
      alert("There was an error processing your request.");
      return null;
    } finally {
      setIsLoading(false);
    }
  };

  // Step 2: Send the transcription to LLM + TTS
  const handleResponse = async (transcription) => {
    if (!transcription) return;

    try {
      setIsProcessing(true);

      // Send transcription to Flask backend for LLM response + TTS
      const response = await axios.post('http://localhost:5000/api/respond', { transcription });
      const { response_text, audio_url } = response.data;

      // Step 2: Display bot's text and audio response
      setMessages((prevMessages) => [
        ...prevMessages,
        { role: 'bot', content: response_text, audioSrc: `http://localhost:5000${audio_url}` }  // Bot's text reply and audio link
      ]);
    } catch (error) {
      console.error('Error:', error);
      alert("There was an error generating the response.");
    } finally {
      setIsProcessing(false);
    }
  };

  // Handle direct text input (bypassing transcription)
  const handleTextResponse = async () => {
    try {
      setIsLoading(true);
      setIsProcessing(true);

      // Send the typed input directly to the backend for LLM + TTS
      const response = await axios.post('http://localhost:5000/api/respond_text', { text: typedInput });
      const { response_text, audio_url } = response.data;

      // Step 2: Display bot's text and audio response
      setMessages((prevMessages) => [
        ...prevMessages,
        { role: 'user', content: typedInput },  // Display user's typed input
        { role: 'bot', content: response_text, audioSrc: `http://localhost:5000${audio_url}` }  // Bot's text reply and audio link
      ]);
    } catch (error) {
      console.error('Error:', error);
      alert("There was an error generating the response.");
    } finally {
      setIsLoading(false);
      setIsProcessing(false);
      setTypedInput("");  // Clear the typed input field
    }
  };

  // Handle form submit based on input type (audio or text)
  const handleSubmit = async (e) => {
    e.preventDefault();

    if (selectedFile) {
      // Step 1: Transcribe the audio
      const transcription = await handleTranscribe();

      // Step 2: Send transcription to LLM + TTS
      await handleResponse(transcription);
    } else if (typedInput) {
      // Handle direct text input
      await handleTextResponse();
    } else {
      alert("Please provide either an audio file or typed text input.");
    }
  };

  return (
    <div className="chat-container">
      <div className="chat-box">
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.role}`}>
            <div className="message-content">
              {msg.role === 'bot' && msg.audioSrc ? (
                <React.Fragment>
                  <p>{msg.content}</p> {/* Display bot's text response */}
                  <audio controls>
                    <source src={msg.audioSrc} type="audio/wav" />
                    Your browser does not support the audio element.
                  </audio>
                </React.Fragment>
              ) : (
                <p>{msg.content}</p> {/* Display user's transcription or typed input */}
              )}
            </div>
          </div>
        ))}

        {isProcessing && (
          <div className="message bot">
            <div className="message-content typing-indicator">
              <span className="dot"></span>
              <span className="dot"></span>
              <span className="dot"></span>
            </div>
          </div>
        )}
      </div>

      <form onSubmit={handleSubmit} className="input-container">
        <input type="file" accept="audio/*" onChange={handleFileChange} />
        <input
          type="text"
          value={typedInput}
          onChange={handleTypedInputChange}
          placeholder="Type your message..."
          disabled={isLoading || isProcessing}
        />
        <button type="submit" disabled={isLoading || isProcessing}>
          {isLoading || isProcessing ? 'Processing...' : 'Send'}
        </button>
      </form>
    </div>
  );
}

export default App;
